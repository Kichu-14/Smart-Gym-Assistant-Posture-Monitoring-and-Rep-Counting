{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092cbab6-5d9d-4cc8-8203-4b2e4665d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b51d35-b3b7-42e8-9623-ed9091ce6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196b7c7d-0e18-468f-83fe-a97390115241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('Brain1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a605418-2a1b-4c3e-803e-72db4437638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e7d88f-95b8-4259-a1d3-716b1b78a175",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling MaxPooling2D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 2 from 1 for '{{node sequential_1/max_pooling2d_1/MaxPool2d}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_1/conv2d_1/Relu)' with input shapes: [32,638,1,32].\u001b[0m\n\nArguments received by MaxPooling2D.call():\n  • inputs=tf.Tensor(shape=(32, 638, 1, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     38\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[1;32m---> 39\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m Y_pred\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (Y_pred\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Poonam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Poonam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling MaxPooling2D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 2 from 1 for '{{node sequential_1/max_pooling2d_1/MaxPool2d}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_1/conv2d_1/Relu)' with input shapes: [32,638,1,32].\u001b[0m\n\nArguments received by MaxPooling2D.call():\n  • inputs=tf.Tensor(shape=(32, 638, 1, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Function to calculate the angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point (the joint)\n",
    "    c = np.array(c)  # Last point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360.0 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\Poonam\\\\OneDrive - Ishaan\\\\Desktop\\\\Ishaan\\\\Assignments\\\\Sem5\\\\FML\\\\Project\\\\Codes_FML\\\\archive\\\\Correct sequence\\\\Copy of push up 1.mp4\")\n",
    "\n",
    "# Push-up counter variables\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "# Setup Mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        Y_pred = model.predict(image)\n",
    "        Y_pred = Y_pred>0.5\n",
    "        if (Y_pred==0):\n",
    "            pred = 'Correct'\n",
    "        else:\n",
    "            pred = 'Wrong'\n",
    "\n",
    "            print(\"Our Prediction is :\", pred)\n",
    "\n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get coordinates for angle 1 (shoulder-hip-knee)\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "\n",
    "            # Calculate angle 1 (shoulder-hip-knee)\n",
    "            angle_1 = calculate_angle(shoulder, hip, knee)\n",
    "\n",
    "            # Get coordinates for angle 2 (shoulder-elbow-wrist)\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angle 2 (shoulder-elbow-wrist)\n",
    "            angle_2 = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "          \n",
    "\n",
    "            # Visualize both angles on the video feed\n",
    "            cv2.putText(image, f\"Angle 1: {int(angle_1)}\",\n",
    "                        tuple(np.multiply(hip, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, f\"Angle 2: {int(angle_2)}\",\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Push-up counter logic\n",
    "            if angle_1 > 160 and angle_2 > 160:  # Body is up\n",
    "                stage = \"up\"\n",
    "            if angle_1 > 160 and angle_2 < 40 and stage == \"up\":  # Body is down\n",
    "                stage = \"down\"\n",
    "                counter += 1\n",
    "                print(counter)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Render push-up counter\n",
    "        # Setup status box\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (0, 165, 255), -1)\n",
    "\n",
    "        # Rep data\n",
    "        cv2.putText(image, \"REPS:\", (15, 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter),\n",
    "                    (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Render pose landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Display video feed with landmarks\n",
    "        cv2.imshow('Push-up Counter', image)\n",
    "\n",
    "        # Break loop on 'q' key press\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "   \n",
    "\n",
    "# Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2396a3-24fe-44a8-9523-8f14508f619b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
