{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7db40a-a7ae-42ce-bf9b-90b7f424c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Correct sequence', 'Wrong sequence']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir('archive')\n",
    "\n",
    "label_types = os.listdir('archive')\n",
    "print (label_types) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6826c0d-de66-4f3a-be4e-fe2a54e5b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tag                                        video_name\n",
      "0  Correct sequence    archive/Correct sequence/Copy of push up 1.mp4\n",
      "1  Correct sequence  archive/Correct sequence/Copy of push up 100.mp4\n",
      "2  Correct sequence  archive/Correct sequence/Copy of push up 101.mp4\n",
      "3  Correct sequence  archive/Correct sequence/Copy of push up 102.mp4\n",
      "4  Correct sequence  archive/Correct sequence/Copy of push up 113.mp4\n",
      "               tag                                     video_name\n",
      "95  Wrong sequence  archive/Wrong sequence/Copy of push up 55.mp4\n",
      "96  Wrong sequence  archive/Wrong sequence/Copy of push up 56.mp4\n",
      "97  Wrong sequence  archive/Wrong sequence/Copy of push up 57.mp4\n",
      "98  Wrong sequence  archive/Wrong sequence/Copy of push up 58.mp4\n",
      "99  Wrong sequence  archive/Wrong sequence/Copy of push up 81.mp4\n"
     ]
    }
   ],
   "source": [
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir('archive' + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str('archive' + '/' +item) + '/' + room))\n",
    "    \n",
    "# Build a dataframe        \n",
    "train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5449ad45-cb9b-4874-898b-ed151207c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c56310ba-b2fe-4868-a222-8115872ce7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e55476-1ddd-40bb-b639-a2167e4e3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 113.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 79.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 164.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 144.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>archive/Wrong sequence/Copy of push up 37.mp4</td>\n",
       "      <td>Wrong sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 129.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 4.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 3.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>archive/Correct sequence/Copy of push up 186.mp4</td>\n",
       "      <td>Correct sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>archive/Wrong sequence/23.mp4</td>\n",
       "      <td>Wrong sequence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                        video_name  \\\n",
       "4            4  archive/Correct sequence/Copy of push up 113.mp4   \n",
       "46          46   archive/Correct sequence/Copy of push up 79.mp4   \n",
       "27          27  archive/Correct sequence/Copy of push up 164.mp4   \n",
       "21          21  archive/Correct sequence/Copy of push up 144.mp4   \n",
       "91          91     archive/Wrong sequence/Copy of push up 37.mp4   \n",
       "9            9  archive/Correct sequence/Copy of push up 129.mp4   \n",
       "40          40    archive/Correct sequence/Copy of push up 4.mp4   \n",
       "39          39    archive/Correct sequence/Copy of push up 3.mp4   \n",
       "34          34  archive/Correct sequence/Copy of push up 186.mp4   \n",
       "65          65                     archive/Wrong sequence/23.mp4   \n",
       "\n",
       "                 tag  \n",
       "4   Correct sequence  \n",
       "46  Correct sequence  \n",
       "27  Correct sequence  \n",
       "21  Correct sequence  \n",
       "91    Wrong sequence  \n",
       "9   Correct sequence  \n",
       "40  Correct sequence  \n",
       "39  Correct sequence  \n",
       "34  Correct sequence  \n",
       "65    Wrong sequence  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ddda84-a5ba-4249-a4b7-39c517fd9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=244\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41cdcea0-6bbe-442b-be64-54b58513d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63f1290-d157-4314-bb5b-b50da04cb400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Correct sequence', 'Wrong sequence']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d24688-e60c-408c-8f16-80cdb8fb6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84ad36e-f4c3-4874-85b2-4627a3c88519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (100, 20, 2048)\n",
      "Frame masks in train set: (100, 20)\n",
      "train_labels in train set: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    \n",
    "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
    "    labels = df[\"tag\"].values\n",
    "    \n",
    "    #convert classlabels to label encoding\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affa885a-3c56-4e33-a9d5-17309c2ddc9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "def get_sequence_model():\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # GRU layers with masking\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    \n",
    "    # Binary classification output layer\n",
    "    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    # Compile with binary_crossentropy and accuracy as the metric\n",
    "    rnn_model.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "EPOCHS = 80\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier.weights.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([train_data[0], train_data[1]], train_labels)\n",
    "    print(f\"Train accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "# Run the experiment with the binary model\n",
    "_, sequence_model = run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da79f7bd-3472-46ad-a8d9-974c10e4688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Poonam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', input_shape = (100,100,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(71, (3, 3), strides=(2,2), padding=\"same\", dilation_rate=(1,1), activation='relu')),\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efd67484-90ac-4e30-b6c9-4a901d0abf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train video path: archive/Correct sequence/Copy of push up 6.mp4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "  Correct sequence: 49.93%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"train\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "train_video = np.random.choice(train_df[\"video_name\"].values.tolist())\n",
    "print(f\"Train video path: {train_video}\")\n",
    "\n",
    "Train_frames = sequence_prediction(train_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b74c18-6ae6-43bd-a966-980a9049aedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
